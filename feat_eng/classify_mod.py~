from csv import DictReader, DictWriter

import numpy as np
from numpy import array

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import SGDClassifier
# AA CHANGE: Added for debugging and making features
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from nltk.corpus import wordnet as wn
from nltk.util import ngrams

kTARGET_FIELD = 'spoiler'
kTEXT_FIELD = 'sentence'

class Analyzer:
    def __init__(self, word, before, after, prev, next, char):
        self.word = word
        self.after = after
        self.before = before
        self.prev = prev
        self.next = next
        self.char = char

    def __call__(self, feature_string):
        feats = feature_string.split()

        if self.word:
            yield feats[0]

        if self.after:
            for ii in [x for x in feats if x.startswith("A:")]:
                yield ii
        if self.before:
            for ii in [x for x in feats if x.startswith("B:")]:
                yield ii
        if self.prev:
            for ii in [x for x in feats if x.startswith("P:")]:
                yield ii
        if self.next:
            for ii in [x for x in feats if x.startswith("N:")]:
                yield ii
        if self.char:
            for ii in [x for x in feats if x.startswith("C:")]:
                yield ii

class Featurizer:
    def __init__(self,Analyzer):
        #self.vectorizer = TfidfVectorizer(analyzer='word',strip_accents='ascii',ngram_range=(1,4),stop_words='english') #TfidfVectorizer() #CountVectorizer()
	self.vectorizer = HashingVectorizer(analyzer=Analyzer)

    def train_feature(self, examples):
        return self.vectorizer.fit_transform(examples)

    def test_feature(self, examples):
        return self.vectorizer.transform(examples)		
		
    def show_top10(self, classifier, categories):
        feature_names = np.asarray(self.vectorizer.get_feature_names())
        if len(categories) == 2:
            top10 = np.argsort(classifier.coef_[0])[-10:]
            bottom10 = np.argsort(classifier.coef_[0])[:10]
            print("Pos: %s" % " ".join(feature_names[top10]))
            print("Neg: %s" % " ".join(feature_names[bottom10]))
        else:
            for i, category in enumerate(categories):
                top10 = np.argsort(classifier.coef_[i])[-10:]
                print("%s: %s" % (category, " ".join(feature_names[top10])))


# AA CHANGE: Added from example script
def accuracy(classifier, x, y):
    predictions = classifier.predict(x)
    #cm = confusion_matrix(y, predictions)

    print("Accuracy: %f" % accuracy_score(y, predictions))

def all_examples(limit, data_set):
    sent_num = 0
    for ii in data_set:
        sent_num += 1
        if limit > 0 and sent_num > limit:
            break

        for jj in xrange(len(ii)):
            ex = example(ii, jj)
	    yield ex

def example(sentence, position):
        print sentence
        print position
        word = sentence[position][0]
        ex = word
        if position > 0:
            prev = " P:%s" % sentence[position - 1][0]
        else:
            prev = ""

        if position < len(sentence) - 1:
            next = " N:%s" % sentence[position + 1][0]
        else:
            next = ''

        all_before = " " + " ".join(["B:%s" % x[0]
                                     for x in sentence[:position]])
        all_after = " " + " ".join(["A:%s" % x[0]
                                    for x in sentence[(position + 1):]])

        char = ' '
        padded_word = "~%s^" % sentence[position][0]
        for ngram_length in xrange(2, 5):
            char += ' ' + " ".join("C:%s" % "".join(cc for cc in x)
                                   for x in ngrams(padded_word, ngram_length))
        ex += char

        ex += prev
        ex += next
        ex += all_after
        ex += all_before

        return ex	

				
	
if __name__ == "__main__":

    # Cast to list to keep it all in memory
    train = list(DictReader(open("../data/spoilers/train.csv", 'r')))
    test = list(DictReader(open("../data/spoilers/test.csv", 'r')))
    word = True
    all_before = False
    all_after = False
    one_before = False
    one_after = False
    characters = False
    analyzer = Analyzer(word, all_before, all_after, one_before, one_after, characters)
    #feat = Featurizer(analyzer)					
    labels = []
    for line in train:
        if not line[kTARGET_FIELD] in labels:
            labels.append(line[kTARGET_FIELD])

    print("Label set: %s" % str(labels))
    #x_train = feat.train_feature(ex for ex in all_examples(len(train),train))
    #x_test = feat.test_feature(ex for ex in all_examples(len(test),test))
    vectorizer = HashingVectorizer(analyzer=Analyzer)
    x_train = vectorizer.fit_transform(ex for ex, tgt in
                                       all_examples(len(train),(x[kTEXT_FIELD] for x in train)))
    x_test = vectorizer.fit_transform(ex for ex, tgt in
                                      all_examples(len(test),(x[kTEXT_FIELD] for x in test)))

    y_train = array(list(labels.index(x[kTARGET_FIELD])
                         for x in train))

    print(len(train), len(y_train))
    print(set(y_train))

    # Train classifier
    lr = SGDClassifier(loss='log', penalty='l2', shuffle=True)
    lr.fit(x_train, y_train)

    feat.show_top10(lr, labels)
    # AA CHANGE: Add debug accuracy 
    print("TRAIN\n-------------------------")
    accuracy(lr,x_train,y_train)

    predictions = lr.predict(x_test)
    o = DictWriter(open("predictions.csv", 'w'), ["id", "spoiler"])
    o.writeheader()
    for ii, pp in zip([x['id'] for x in test], predictions):
        d = {'id': ii, 'spoiler': labels[pp]}
        o.writerow(d)
